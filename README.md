# CogMod-Cliffworld

You have to \texttt{git clone} the project or download the ZIP file. Next, you have to use \texttt{python CliffWorld.py} or python3 if you're using Python 3. In the main function in CliffWorld.py, you can define a board by \texttt{c = Cliff()}. Furthermore you can define an agent by \texttt{ag = Agent(epsilon = 0.1, lr=0.1, sarsa=True, softmax=False)}. All these variables are changeable. To train the agent you execute: \texttt{ag.learn(500)}. 500 is the amount of iterations, this is also changeable. If you would like to print the optimal policy you would need to use: \texttt{calculateOptimalPolicy(ag)}, where ag is the defined agent. To only run the agent once use the learn function with only 1 iteration, and then use the calculateOptimalPolicy function.
You can also re-run the plot calculations, this is explained in the code. You have to uncomment what you want to run in the main function. To also get the correct plot label names you also have to uncomment the code in the \texttt{plot_cumreward_normalized} function.
